{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0b3137",
   "metadata": {},
   "source": [
    "# Efb0 infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f90f7",
   "metadata": {},
   "source": [
    "## Import tools and CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb1a920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('E:/HMS2024/code/model1/efb0/tf_efficientnet_b0.ns_jft_in1k_0_v2.pt'), WindowsPath('E:/HMS2024/code/model1/efb0/tf_efficientnet_b0.ns_jft_in1k_1_v2.pt'), WindowsPath('E:/HMS2024/code/model1/efb0/tf_efficientnet_b0.ns_jft_in1k_2_v2.pt'), WindowsPath('E:/HMS2024/code/model1/efb0/tf_efficientnet_b0.ns_jft_in1k_3_v2.pt'), WindowsPath('E:/HMS2024/code/model1/efb0/tf_efficientnet_b0.ns_jft_in1k_4_v2.pt')]\n"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pywt, librosa\n",
    "\n",
    "USE_WAVELET = None \n",
    "\n",
    "NAMES = ['LL','LP','RP','RR','LZ','RZ']\n",
    "\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2'],\n",
    "         ['Fp1','Fz','Cz','Pz','O1'],\n",
    "         ['Fp2','Fz','Cz','Pz','O2'],\n",
    "        ]\n",
    "\n",
    "class CFG:\n",
    "    base_dir = pathlib.Path(\"E:\\HMS2024\")\n",
    "    path_test = base_dir / \"code/model1/validation.csv\"\n",
    "    path_submission = base_dir / \"sample_submission.csv\"\n",
    "    spec_dir = base_dir / \"validation_spectrograms\"\n",
    "    model_name = \"tf_efficientnet_b0_ns\"\n",
    "\n",
    "    model_weights = sorted(list(\n",
    "        pathlib.Path(\"E:\\HMS2024\\code\\model1\\efb0\").glob(\"*_v2.pt\")\n",
    "    ))\n",
    "    \n",
    "    print(model_weights)\n",
    "\n",
    "    transform = transforms.Resize((768, 768), antialias=False)\n",
    "    batch_size = 16\n",
    "    label_columns = [\n",
    "        \"seizure_vote\",\n",
    "        \"lpd_vote\",\n",
    "        \"gpd_vote\",\n",
    "        \"lrda_vote\",\n",
    "        \"grda_vote\",\n",
    "        \"other_vote\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44752f50",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "92dc3617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DENOISE FUNCTION\n",
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "def denoise(x, wavelet='haar', level=1):    \n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/0.6745) * maddest(coeff[-level])\n",
    "\n",
    "    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "\n",
    "    ret=pywt.waverec(coeff, wavelet, mode='per')\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def spectrogram_from_eeg(parquet_path, display=False):\n",
    "    \n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg)-10_000)//2\n",
    "    eeg = eeg.iloc[middle:middle+10_000]\n",
    "    \n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((192,768,6),dtype='float32')\n",
    "    \n",
    "    if display: plt.figure(figsize=(10,12))\n",
    "    signals = []\n",
    "    for k in range(6):\n",
    "        COLS = FEATS[k]\n",
    "        \n",
    "        for kk in range(4):\n",
    "        \n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n",
    "\n",
    "            # FILL NANS\n",
    "            m = np.nanmean(x)\n",
    "            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "            else: x[:] = 0\n",
    "\n",
    "            # DENOISE\n",
    "            if USE_WAVELET:\n",
    "                x = denoise(x, wavelet=USE_WAVELET)\n",
    "            signals.append(x)\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//768, \n",
    "                  n_fft=1024, n_mels=192, fmin=0, fmax=20, win_length=128)\n",
    "\n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1]//32)*32\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "\n",
    "            # STANDARDIZE TO -1 TO 1\n",
    "            mel_spec_db = (mel_spec_db+40)/40 \n",
    "            img[:,:,k] += mel_spec_db\n",
    "                \n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:,:,k] /= 4.0\n",
    "        \n",
    "        if display:\n",
    "            plt.subplot(3,2,k+1)\n",
    "            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n",
    "            plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n",
    "            \n",
    "    if display: \n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,7))\n",
    "        offset = 0\n",
    "        for k in range(6):\n",
    "            if k>0: offset -= signals[3-k].min()\n",
    "            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n",
    "            offset += signals[3-k].max()\n",
    "        plt.legend()\n",
    "        plt.title(f'EEG {eeg_id} Signals')\n",
    "        plt.show()\n",
    "        print(); print('#'*25); print()\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    m, s = x.mean(), x.std()\n",
    "    x = (x - m) / (s + 1e-6)\n",
    "    return x\n",
    "\n",
    "def preprocess2(x):\n",
    "    x = np.clip(x, np.exp(-6), np.exp(10))\n",
    "    x = np.log(x)\n",
    "    m, s = x.mean(), x.std()\n",
    "    x = (x - m) / (s + 1e-6)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e23a6",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51fc64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=CFG.transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        # input\n",
    "        x = all_eegs2[row.eeg_id]\n",
    "        x = [x[:,:,i+0:i+1] for i in range(6)]\n",
    "        x1 = np.concatenate(x,axis=0)[:,:,0]\n",
    "        x1 = preprocess(x1)\n",
    "        # input\n",
    "        x = pd.read_parquet(row.path)\n",
    "        x = x.fillna(-1).values[:, 1:].T\n",
    "        x2 = preprocess2(x)\n",
    "        x2 = torch.Tensor(x2[None, :])\n",
    "        x2 = np.array(CFG.transform(x2))[0]\n",
    "        x = np.concatenate([x1,x2])\n",
    "\n",
    "        \n",
    "        x = torch.Tensor(x[None, :])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        # output\n",
    "        y = np.array(row.loc[CFG.label_columns].values, 'float32')\n",
    "        y = torch.Tensor(y)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b8388",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a32ac47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0628e8a229034d8e87862a6a3f3ca57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"E:\\HMS2024\\code\\model3/validation.csv\")[['eeg_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote', 'spectrogram_id', 'patient_id']]\n",
    "submission['path'] = submission['spectrogram_id'].apply(lambda x: f\"E:/HMS2024/validation_spectrograms/{x}.parquet\")\n",
    "\n",
    "PATH2 = 'model1/validation_eegs/'\n",
    "DISPLAY = False\n",
    "EEG_IDS2 = submission.eeg_id.unique()\n",
    "all_eegs2 = {}\n",
    "\n",
    "for i,eeg_id in enumerate(tqdm(EEG_IDS2)):\n",
    "    img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n",
    "    all_eegs2[eeg_id] = img\n",
    "    \n",
    "data_ds = SpecDataset(df=submission)\n",
    "data_loader = DataLoader(dataset=data_ds)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = timm.create_model(model_name=CFG.model_name, pretrained=False, num_classes=6, in_chans=1)\n",
    "model.to(DEVICE)\n",
    "\n",
    "prediction = pd.DataFrame(0.0, columns=CFG.label_columns, index=submission.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d054088",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "535d525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: E:\\HMS2024\\code\\model1\\efb0\\tf_efficientnet_b0.ns_jft_in1k_0_v2.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9c120a163743b8b4e124d5e185e683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model 1: E:\\HMS2024\\code\\model1\\efb0\\tf_efficientnet_b0.ns_jft_in1k_1_v2.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915561f1b9e44045b0004e9aff28d681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model 2: E:\\HMS2024\\code\\model1\\efb0\\tf_efficientnet_b0.ns_jft_in1k_2_v2.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e33f625b5146f780c38bc22a94b592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model 3: E:\\HMS2024\\code\\model1\\efb0\\tf_efficientnet_b0.ns_jft_in1k_3_v2.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d11bc8992984a70b823d31757c301bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model 4: E:\\HMS2024\\code\\model1\\efb0\\tf_efficientnet_b0.ns_jft_in1k_4_v2.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289b8621cb4d495bb64c5d5d1aed53ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, path_weight in enumerate(CFG.model_weights):\n",
    "    print(f\"Model {i}: {path_weight}\")\n",
    "    model.load_state_dict(torch.load(path_weight))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        res = []\n",
    "        for x, y in tqdm(data_loader):\n",
    "            x = x.to(DEVICE)\n",
    "            pred = model(x)\n",
    "            pred = F.softmax(pred, dim=1)\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            res.append(pred)\n",
    "        res = np.concatenate(res)\n",
    "        res = pd.DataFrame(res, columns=CFG.label_columns, index=submission.iloc[:60,:].index)\n",
    "\n",
    "        prediction = prediction + res\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "prediction = prediction / len(CFG.model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8ffe5",
   "metadata": {},
   "source": [
    "## display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9b38231",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission\n",
    "submission[CFG.label_columns] = prediction\n",
    "submission = submission[[\"eeg_id\"] + CFG.label_columns]\n",
    "submission.to_csv(\"efficientnet_b0_v2_validation_result.csv\", index=None)\n",
    "\n",
    "result = pd.read_csv('efficientnet_b0_v2_validation_result.csv')\n",
    "result.columns = ['eeg_id', 'seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "train_df = pd.read_csv('E:\\HMS2024/train.csv')\n",
    "res = train_df[train_df['eeg_id'].isin(result['eeg_id'])]\n",
    "b0result = result.merge(res[['eeg_id', 'expert_consensus', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']], on='eeg_id', how='left')\n",
    "b0result = b0result.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f3996",
   "metadata": {},
   "source": [
    "# Efb1 infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1c75d",
   "metadata": {},
   "source": [
    "## 导入工具包及config文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d73e84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=Warning)\n",
    "\n",
    "class Config:\n",
    "    seed=42\n",
    "    image_transform=transforms.Resize((512, 512))\n",
    "    num_folds=5\n",
    "    \n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(Config.seed)\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca473af",
   "metadata": {},
   "source": [
    "## 加载数据模型完成推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4a42f5",
   "metadata": {},
   "source": [
    "EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e9e1103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211864690d114c5bb4cd232438141d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load EfficientNetB1\n",
    "for k in range(Config.num_folds):\n",
    "    model_effnet_b2 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n",
    "    model_effnet_b2.to('cuda')\n",
    "    model_effnet_b2.load_state_dict(torch.load(f'./model3/efb1_v2/efficientnet_b1_fold{k}_v2.pth', map_location=torch.device('cpu')))\n",
    "    models.append(model_effnet_b2)\n",
    "\n",
    "submission = pd.read_csv(\"E:\\HMS2024\\code\\model3/validation.csv\")[['eeg_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote', 'spectrogram_id', 'patient_id']]\n",
    "submission = submission\n",
    "\n",
    "submission['path'] = submission['spectrogram_id'].apply(lambda x: f\"E:/HMS2024/validation_spectrograms/{x}.parquet\")\n",
    "\n",
    "paths = submission['path'].values\n",
    "test_preds = []\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    eps = 1e-6\n",
    "    data = pd.read_parquet(path)\n",
    "    data = data.fillna(-1).values[:, 1:].T\n",
    "    data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "    data = np.log(data)\n",
    "    \n",
    "    data_mean = data.mean(axis=(0, 1))\n",
    "    data_std = data.std(axis=(0, 1))\n",
    "    data = (data - data_mean) / (data_std + eps)\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "    data = Config.image_transform(data_tensor).to('cuda')\n",
    "\n",
    "    test_pred = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = F.softmax(model(data.unsqueeze(0)))[0]\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        test_pred.append(pred)\n",
    "        \n",
    "    weighted_pred = np.mean(test_pred[:Config.num_folds], axis=0)\n",
    "    test_preds.append(weighted_pred)\n",
    "\n",
    "test_preds = torch.tensor(test_preds).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75db01",
   "metadata": {},
   "source": [
    "## display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7197cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [[attr1, attr2, attr3, attr4, attr5, attr6] for attr1, attr2, attr3, attr4, attr5, attr6 in test_preds]\n",
    "eegid = submission['eeg_id']\n",
    "sub = pd.DataFrame(l, columns=['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other'])\n",
    "sub['eeg_id'] = eegid\n",
    "\n",
    "# 查看合并后的DataFrame\n",
    "sub.to_csv('efficientnet_b1_v2_validation_result.csv', index=False)\n",
    "\n",
    "result = pd.read_csv('efficientnet_b1_v2_validation_result.csv')\n",
    "train_df = pd.read_csv('E:\\HMS2024/train.csv')\n",
    "res = train_df[train_df['eeg_id'].isin(result['eeg_id'])]\n",
    "b1result = result.merge(res[['eeg_id', 'expert_consensus', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']], on='eeg_id', how='left')\n",
    "b1result = b1result.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f52a8",
   "metadata": {},
   "source": [
    "# ResNet34-BiGRU infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebe04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "import scipy.signal as scisig\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import (\n",
    "    ReduceLROnPlateau,\n",
    "    OneCycleLR,\n",
    "    CosineAnnealingLR,\n",
    "    CosineAnnealingWarmRestarts,\n",
    ")\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from sklearn.model_selection import GroupKFold,KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "class CFG:\n",
    "    VERSION = 88\n",
    "\n",
    "    model_name = \"resnet1d_gru\"\n",
    "\n",
    "    seed = 2024\n",
    "    batch_size = 32\n",
    "    num_workers = 0\n",
    "\n",
    "    fixed_kernel_size = 5\n",
    "    # kernels = [3, 5, 7, 9]\n",
    "    # linear_layer_features = 424\n",
    "    kernels = [3, 5, 7, 9, 11]\n",
    "    #linear_layer_features = 448  # Full Signal = 10_000\n",
    "    #linear_layer_features = 352  # Half Signal = 5_000\n",
    "    linear_layer_features = 304   # 1/5  Signal = 2_000\n",
    "\n",
    "    seq_length = 50  # Second's\n",
    "    sampling_rate = 200  # Hz\n",
    "    nsamples = seq_length * sampling_rate\n",
    "    out_samples = nsamples // 5\n",
    "\n",
    "    # bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n",
    "    # rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n",
    "    freq_channels = []  # [(8.0, 12.0)]; [(0.5, 4.5)]\n",
    "    filter_order = 2\n",
    "    random_close_zone = 0.0  # 0.2\n",
    "        \n",
    "    target_cols = [\n",
    "        \"seizure_vote\",\n",
    "        \"lpd_vote\",\n",
    "        \"gpd_vote\",\n",
    "        \"lrda_vote\",\n",
    "        \"grda_vote\",\n",
    "        \"other_vote\",\n",
    "    ]\n",
    "\n",
    "    # target_preds = [x + \"_pred\" for x in target_cols]\n",
    "    # label_to_num = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n",
    "    # num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "\n",
    "    map_features = [\n",
    "        (\"Fp1\", \"T3\"),\n",
    "        (\"T3\", \"O1\"),\n",
    "        (\"Fp1\", \"C3\"),\n",
    "        (\"C3\", \"O1\"),\n",
    "        (\"Fp2\", \"C4\"),\n",
    "        (\"C4\", \"O2\"),\n",
    "        (\"Fp2\", \"T4\"),\n",
    "        (\"T4\", \"O2\"),\n",
    "        #('Fz', 'Cz'), ('Cz', 'Pz'),        \n",
    "    ]\n",
    "\n",
    "    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz']\n",
    "        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']                    \n",
    "    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n",
    "    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n",
    "\n",
    "    # eeg_features = [row for row in feature_to_index]\n",
    "    # eeg_feat_size = len(eeg_features)\n",
    "    \n",
    "    n_map_features = len(map_features)\n",
    "    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n",
    "    target_size = len(target_cols)\n",
    "    \n",
    "    PATH = \".\"\n",
    "    test_eeg = \"E:/HMS2024/code/model1/validation_eegs/\"\n",
    "    test_csv = \"./validation.csv\"\n",
    "\n",
    "koef_1 = 1.0\n",
    "model_weights = [\n",
    "    {\n",
    "        'bandpass_filter':{'low':0.5, 'high':20, 'order':2}, \n",
    "        'file_data': \n",
    "        [\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v82/pop_1_weight_oof/*_best.pth\"},\n",
    "            {'koef':koef_1, 'file_mask':\"E:\\HMS2024\\code\\model2\\pop_1_weight_oof_n9/*_best.pth\"},  ## Set path\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "def init_logger(log_file=\"./test.log\"):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x  # quantized\n",
    "\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(\n",
    "    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n",
    "):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n",
    "    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n",
    "    y = y[0:-1:4]\n",
    "    return y\n",
    "\n",
    "def eeg_from_parquet(\n",
    "    parquet_path: str, display: bool = False, seq_length=CFG.seq_length) -> np.ndarray:\n",
    "\n",
    "    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n",
    "    rows = len(eeg)\n",
    "\n",
    "    offset = (rows - CFG.nsamples) // 2\n",
    "    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        offset = 0\n",
    "\n",
    "    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n",
    "\n",
    "    for index, feature in enumerate(CFG.eeg_features):\n",
    "        x = eeg[feature].values.astype(\"float32\") \n",
    "\n",
    "        mean = np.nanmean(x)\n",
    "        nan_percentage = np.isnan(x).mean()  \n",
    "\n",
    "        if nan_percentage < 1:  \n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else: \n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "\n",
    "        if display:\n",
    "            if index != 0:\n",
    "                offset += x.max()\n",
    "            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n",
    "            offset -= x.min()\n",
    "\n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"EEG {name}\", size=16)\n",
    "        plt.show()\n",
    "    return data\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        eegs: Dict[int, np.ndarray],\n",
    "        mode: str = \"train\",\n",
    "        downsample: int = None,\n",
    "        bandpass_filter: Dict[str, Union[int, float]] = None,\n",
    "        rand_filter: Dict[str, Union[int, float]] = None,\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = downsample\n",
    "        self.bandpass_filter = bandpass_filter\n",
    "        self.rand_filter = rand_filter\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y_prob = self.__data_generation(index)\n",
    "        if self.downsample is not None:\n",
    "            X = X[:: self.downsample, :]\n",
    "        output = {\n",
    "            \"eeg\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "\n",
    "        X = np.zeros(\n",
    "            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n",
    "        )  # Size=(10000, 14)\n",
    "\n",
    "        row = self.df.iloc[index]\n",
    "        data = self.eegs[row.eeg_id]  # Size=(10000, 8)\n",
    "        if CFG.nsamples != CFG.out_samples:\n",
    "            if self.mode != \"train\":\n",
    "                offset = (CFG.nsamples - CFG.out_samples) // 2\n",
    "            else:\n",
    "                #offset = random.randint(0, CFG.nsamples - CFG.out_samples)                \n",
    "                offset = ((CFG.nsamples - CFG.out_samples) * random.randint(0, 1000)) // 1000\n",
    "            data = data[offset:offset+CFG.out_samples,:]\n",
    "\n",
    "        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n",
    "            if self.mode == \"train\" and CFG.random_close_zone > 0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:\n",
    "                continue\n",
    "                \n",
    "            diff_feat = (\n",
    "                data[:, CFG.feature_to_index[feat_a]]\n",
    "                - data[:, CFG.feature_to_index[feat_b]]\n",
    "            )  # Size=(10000,)\n",
    "\n",
    "            if not self.bandpass_filter is None:\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "                    \n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, i] = diff_feat\n",
    "\n",
    "        n = CFG.n_map_features\n",
    "        if len(CFG.freq_channels) > 0:\n",
    "            for i in range(CFG.n_map_features):\n",
    "                diff_feat = X[:, i]\n",
    "                for j, (lowcut, highcut) in enumerate(CFG.freq_channels):\n",
    "                    band_feat = butter_bandpass_filter(\n",
    "                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n",
    "                    )\n",
    "                    X[:, n] = band_feat\n",
    "                    n += 1\n",
    "\n",
    "        for spml_feat in CFG.simple_features:\n",
    "            feat_val = data[:, CFG.feature_to_index[spml_feat]]\n",
    "            \n",
    "            if not self.bandpass_filter is None:\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, n] = feat_val\n",
    "            n += 1\n",
    "            \n",
    "        X = np.clip(X, -1024, 1024)\n",
    "\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n",
    "\n",
    "        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # Size=(6,)\n",
    "        if self.mode != \"test\":\n",
    "            y_prob = row[CFG.target_cols].values.astype(np.float32)\n",
    "\n",
    "        return X, y_prob\n",
    "    \n",
    "class ResNet_1D_Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        downsampling,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.PReLU()\n",
    "        # self.relu_2 = nn.PReLU()\n",
    "        self.relu_1 = nn.Hardswish()\n",
    "        self.relu_2 = nn.Hardswish()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernels,\n",
    "        in_channels,\n",
    "        fixed_kernel_size,\n",
    "        num_classes,\n",
    "        linear_layer_features,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "    ):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=self.planes,\n",
    "                kernel_size=(kernel_size),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                dilation=dilation,\n",
    "                groups=groups,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.ReLU()\n",
    "        # self.relu_2 = nn.ReLU()\n",
    "        self.relu_1 = nn.SiLU()\n",
    "        self.relu_2 = nn.SiLU()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=self.planes,\n",
    "            out_channels=self.planes,\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.block = self._make_resnet_layer(\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=1,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            padding=fixed_kernel_size // 2,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.in_channels,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            # dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=linear_layer_features, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(\n",
    "        self,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        blocks=9,\n",
    "        padding=0,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "            )\n",
    "            layers.append(\n",
    "                ResNet_1D_Block(\n",
    "                    in_channels=self.planes,\n",
    "                    out_channels=self.planes,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    downsampling=downsampling,\n",
    "                    dilation=dilation,\n",
    "                    groups=groups,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]  # <~~\n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "        return new_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_out = self.extract_features(x)\n",
    "        result = self.fc(new_out)\n",
    "        return result\n",
    "    \n",
    "def inference_function(test_loader, model, device):\n",
    "    model.eval()  # set model in evaluation mode\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    with tqdm(test_loader, unit=\"test_batch\", desc=\"Inference\") as tqdm_test_loader:\n",
    "        for step, batch in enumerate(tqdm_test_loader):\n",
    "            X = batch.pop(\"eeg\").to(device)  # send inputs to `device`\n",
    "            batch_size = X.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)  # forward propagation pass\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())  # save predictions\n",
    "\n",
    "    prediction_dict[\"predictions\"] = np.concatenate(\n",
    "        preds\n",
    "    )  # np.array() of shape (fold_size, target_cols)\n",
    "    return prediction_dict\n",
    "\n",
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "# print(f\"Test dataframe shape is: {test_df.shape}\")\n",
    "\n",
    "test_eeg_parquet_paths = glob(CFG.test_eeg + \"*.parquet\")\n",
    "test_eeg_df = pd.read_parquet(test_eeg_parquet_paths[0])\n",
    "test_eeg_features = test_eeg_df.columns\n",
    "# print(f\"There are {len(test_eeg_features)} raw eeg features\")\n",
    "# print(list(test_eeg_features))\n",
    "del test_eeg_df\n",
    "_ = gc.collect()\n",
    "\n",
    "all_eegs = {}\n",
    "eeg_ids = test_df.eeg_id.unique()\n",
    "for i, eeg_id in tqdm(enumerate(eeg_ids)):\n",
    "    # Save EEG to Python dictionary of numpy arrays\n",
    "    eeg_path = CFG.test_eeg + str(eeg_id) + \".parquet\"\n",
    "    data = eeg_from_parquet(eeg_path)\n",
    "    all_eegs[eeg_id] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff07ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "koef_sum = 0\n",
    "koef_count = 0\n",
    "predictions = []\n",
    "files = []\n",
    "    \n",
    "for model_block in model_weights:\n",
    "    test_dataset = EEGDataset(\n",
    "        df=test_df,\n",
    "        batch_size=CFG.batch_size,\n",
    "        mode=\"test\",\n",
    "        eegs=all_eegs,\n",
    "        bandpass_filter=model_block['bandpass_filter']\n",
    "    )\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        output = test_dataset[0]\n",
    "        X = output[\"eeg\"]\n",
    "        print(f\"X shape: {X.shape}\")\n",
    "                \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    model = EEGNet(\n",
    "        kernels=CFG.kernels,\n",
    "        in_channels=CFG.in_channels,\n",
    "        fixed_kernel_size=CFG.fixed_kernel_size,\n",
    "        num_classes=CFG.target_size,\n",
    "        linear_layer_features=CFG.linear_layer_features,\n",
    "    )\n",
    "\n",
    "    for file_line in model_block['file_data']:\n",
    "        koef = file_line['koef']\n",
    "        for weight_model_file in glob(file_line['file_mask']):\n",
    "            files.append(weight_model_file)\n",
    "            checkpoint = torch.load(weight_model_file, map_location=device)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "            model.to(device)\n",
    "            prediction_dict = inference_function(test_loader, model, device)\n",
    "            predict = prediction_dict[\"predictions\"]\n",
    "            predict *= koef\n",
    "            koef_sum += koef\n",
    "            koef_count += 1\n",
    "            predictions.append(predict)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "koef_sum /= koef_count\n",
    "predictions /= koef_sum\n",
    "predictions = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"eeg_id\": test_df.eeg_id.values})\n",
    "sub[CFG.target_cols] = predictions\n",
    "sub.to_csv(\"res1d_validation_result_v1_n9.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
